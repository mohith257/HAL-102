"""
Integration Test - Full VisionMate Pipeline
Tests all modules working together
"""
import cv2
import numpy as np
import sys
import os
import time

# Add parent directory to path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from object_detector import ObjectDetector
from face_recognizer import FaceRecognizer
# from traffic_signal_detector import TrafficSignalDetector  # DISABLED: Too many false positives
from item_tracker import ItemTracker
from audio_feedback import get_audio_feedback
from database import VisionMateDB
from object_memory import ObjectMemory
from spatial_navigator import SpatialNavigator
from voice_command_system import VoiceCommandSystem

# FREE Navigation modules (OpenStreetMap)
from gps_tracker import GPSTracker
from osm_navigator import OSMNavigator
from ultrasonic_sensor import UltrasonicSensor
from obstacle_fusion import ObstacleFusion
from navigation_engine import NavigationEngine
import config


def test_full_pipeline_webcam():
    """Test complete AI pipeline with webcam"""
    print("=" * 60)
    print("VISIONMATE FULL INTEGRATION TEST")
    print("=" * 60)
    
    print("\nInitializing all modules...")
    db = VisionMateDB()
    object_detector = ObjectDetector()
    face_recognizer = FaceRecognizer(db)
    # traffic_detector = TrafficSignalDetector()  # DISABLED: Too many false positives
    item_tracker = ItemTracker(db)
    object_memory = ObjectMemory(db)
    spatial_nav = SpatialNavigator(frame_width=640, frame_height=480)
    audio = get_audio_feedback(use_gtts=False)
    
    # Initialize FREE navigation system (OpenStreetMap)
    gps_tracker = GPSTracker(mock_mode=config.GPS_MOCK_MODE)
    osm_nav = OSMNavigator()
    ultrasonic = UltrasonicSensor(mock_mode=config.ULTRASONIC_MOCK_MODE)
    obstacle_fusion = ObstacleFusion(ultrasonic, frame_width=640, frame_height=480)
    nav_engine = NavigationEngine(
        gps_tracker,
        osm_nav,
        announcement_distance=config.NAVIGATION_ANNOUNCEMENT_DISTANCE,
        reroute_distance=config.NAVIGATION_REROUTE_DISTANCE,
        arrival_distance=config.NAVIGATION_ARRIVAL_DISTANCE
    )
    
    # Start background services
    gps_tracker.start()
    ultrasonic.start()
    
    # Initialize voice command system
    voice_system = VoiceCommandSystem()
    voice_initialized = voice_system.initialize()
    if voice_initialized:
        voice_system.start()
        print("âœ“ Voice command system initialized!")
    else:
        print("âš  Voice command system not available (microphone issue)")
        voice_system = None
    
    print("âœ“ All modules initialized!")
    
    print("\nOpening webcam...")
    print("Controls:")
    print("  Q - Quit")
    print("  E - Enroll face")
    print("  R - Remember object (enroll custom object)")
    print("  L - List remembered objects")
    print("  F - Find item/object location")
    print("  A - Toggle audio feedback")
    print("  N - Toggle navigation guidance (obstacle avoidance)")
    print("  G - GPS Navigation (navigate to destination)")
    print("  M - Advance mock GPS (simulate movement)")
    print("  SPACEBAR - Voice command (button simulation)")
    print("  V - Toggle voice mode")
    if voice_initialized:
        print("\nâœ“ Voice commands available:")
        print("  - 'Remember this [object]' - Enroll object")
        print("  - 'Find my [object]' - Locate object")
        print("  - 'Navigate to [destination]' - GPS navigation")
        print("  - 'Navigate' / 'Stop navigation' - Control obstacle guidance")
        print("  - 'List all items' - Show remembered objects")
    
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âœ— Could not open webcam")
        db.close()
        return
    
    frame_count = 0
    start_time = time.time()
    audio_enabled = True
    navigation_enabled = True  # Enable spatial navigation by default
    voice_mode_enabled = voice_initialized  # Enable voice if available
    seen_faces = set()  # Track faces already announced
    face_announce_interval = 5.0  # Seconds between re-announcing same person
    last_face_announce = {}  # Track when each person was last announced
    last_recognized_faces = []  # Store last recognized face names for nearby context
    last_navigation_announce = 0  # Track when navigation was last announced
    navigation_announce_cooldown = 2.0  # Seconds between navigation announcements
    
    # Object memory state
    enrollment_mode = False
    enrollment_target_obj = None
    enrollment_frames_captured = 0
    enrollment_buffer = []
    last_remembered_announce = {}  # Track announcements to avoid spam
    remember_announce_cooldown = 3.0  # Seconds
    
    # Voice command state
    current_frame = None  # Store current frame for voice commands
    current_objects = []  # Store current objects for voice commands
    
    # GPS Navigation state
    gps_navigation_active = False
    gps_nav_step = 0
    last_gps_update = 0
    gps_update_interval = 2.0  # Update every 2 seconds
    last_gps_announcement = None
    
    # Register voice command handlers
    if voice_system:
        def handle_voice_remember(params):
            """Handle 'remember this [object]' command"""
            nonlocal enrollment_mode, enrollment_target_obj
            
            if enrollment_mode:
                audio.speak_status("Already enrolling an object")
                return
                
            object_name = params.get('object_name', '')
            if not object_name:
                audio.speak_status("Please specify an object name")
                return
            
            # Match object name to detected objects
            matching_objects = [o for o in current_objects if object_name.lower() in o['class_name'].lower()]
            
            if matching_objects:
                obj = matching_objects[0]  # Take first match
                custom_name = f"my{object_name}"  # e.g., "myphone"
                
                try:
                    object_memory.start_enrollment(custom_name, obj['class_name'])
                    enrollment_mode = True
                    enrollment_target_obj = {
                        'custom_name': custom_name,
                        'yolo_class': obj['class_name']
                    }
                    audio.speak_social(f"Starting enrollment for {custom_name}. Keep it steady.")
                    print(f"âœ“ Voice: Enrolling '{custom_name}'")
                except ValueError as e:
                    audio.speak_status(f"Error: {e}")
            else:
                audio.speak_status(f"No {object_name} detected in view")
        
        def handle_voice_find(params):
            """Handle 'find my [object]' command"""
            object_name = params.get('object_name', '')
            if not object_name:
                audio.speak_status("Please specify what to find")
                return
            
            # Try remembered objects
            location = object_memory.get_object_location(object_name)
            if location:
                nearby = location['context'].get('nearby_objects', []) if location['context'] else []
                nearby_str = f" near {', '.join(nearby)}" if nearby else ""
                msg = f"Your {object_name} last seen{nearby_str}"
                audio.speak_navigational(msg)
                print(f"âœ“ Voice: {msg}")
            else:
                # Try item tracker
                loc = item_tracker.query_item_location(object_name)
                if loc:
                    msg = f"Your {object_name} on the {loc}"
                    audio.speak_navigational(msg)
                    print(f"âœ“ Voice: {msg}")
                else:
                    audio.speak_status(f"Haven't seen {object_name}")
        
        def handle_voice_navigate(params):
            """Handle 'navigate' command"""
            nonlocal navigation_enabled
            if not navigation_enabled:
                navigation_enabled = True
                audio.speak_social("Navigation enabled")
                print("âœ“ Voice: Navigation ON")
            else:
                audio.speak_status("Navigation already active")
        
        def handle_voice_stop_navigate(params):
            """Handle 'stop navigation' command"""
            nonlocal navigation_enabled
            if navigation_enabled:
                navigation_enabled = False
                audio.speak_social("Navigation disabled")
                print("âœ“ Voice: Navigation OFF")
            else:
                audio.speak_status("Navigation already off")
        
        def handle_voice_list(params):
            """Handle 'list all items' command"""
            remembered_list = object_memory.list_remembered_objects()
            if remembered_list:
                items = ", ".join([name for name, _ in remembered_list])
                audio.speak_social(f"I remember: {items}")
                print(f"âœ“ Voice: Listed {len(remembered_list)} items")
            else:
                audio.speak_status("No items remembered yet")
        
        def handle_voice_help(params):
            """Handle 'help' command"""
            audio.speak_social("Say: remember this phone, find my keys, navigate to destination, stop navigation, or list all items")
        
        def handle_voice_navigate_to(params):
            """Handle 'navigate to [destination]' command for GPS navigation"""
            nonlocal gps_navigation_active, gps_nav_step, last_gps_announcement
            
            destination = params.get('destination', '')
            if not destination:
                audio.speak_status("Where do you want to go?")
                return
            
            audio.speak_social(f"Navigating to {destination}")
            print(f"\nâœ“ Voice: Starting GPS navigation to {destination}")
            
            # Geocode destination
            dest_coords = osm_nav.geocode_address(destination + ", Bangalore, India")
            if not dest_coords:
                audio.speak_status("Could not find destination")
                print(f"âœ— Geocoding failed for {destination}")
                return
            
            # Get current position
            current_pos = gps_tracker.get_position()
            if not current_pos:
                audio.speak_status("Waiting for GPS signal")
                print("âœ— No GPS signal")
                return
            
            # Get directions
            route = osm_nav.get_directions(current_pos, dest_coords, mode='foot')
            if not route:
                audio.speak_status("Could not find route")
                print("âœ— Routing failed")
                return
            
            # Store route and activate navigation
            osm_nav.current_route = route
            gps_navigation_active = True
            gps_nav_step = 0
            last_gps_announcement = None
            
            # Announce route
            audio.speak_social(f"Route found. {route['total_distance']}. {route['total_duration']}.")
            print(f"âœ“ GPS Navigation started: {len(route['steps'])} steps")
            print(f"  Distance: {route['total_distance']}")
            print(f"  Duration: {route['total_duration']}")
        
        def handle_voice_stop_gps(params):
            """Handle 'stop GPS navigation' command"""
            nonlocal gps_navigation_active
            if gps_navigation_active:
                gps_navigation_active = False
                audio.speak_social("GPS navigation stopped")
                print("âœ“ Voice: GPS navigation stopped")
            else:
                audio.speak_status("No GPS navigation active")
        
        # Register all handlers
        voice_system.register_command_handler('remember', handle_voice_remember)
        voice_system.register_command_handler('find', handle_voice_find)
        voice_system.register_command_handler('navigate', handle_voice_navigate)
        voice_system.register_command_handler('stop_navigate', handle_voice_stop_navigate)
        voice_system.register_command_handler('list', handle_voice_list)
        voice_system.register_command_handler('help', handle_voice_help)
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        frame_count += 1
        
        # Create display frame
        display = frame.copy()
        
        # 1. Object Detection
        objects = object_detector.detect(frame)
        display = object_detector.draw_detections(display, objects)
        
        # Store current state for voice commands
        current_frame = frame.copy()
        current_objects = objects
        
        # 1b. Recognize remembered objects
        remembered_objects = []
        object_to_custom_name = {}  # Map object IDs to custom names
        
        if not enrollment_mode:  # Don't interfere with enrollment
            for obj in objects:
                bbox = (obj['bbox'][0], obj['bbox'][1], obj['bbox'][2], obj['bbox'][3])
                match = object_memory.recognize_object(frame, bbox, obj['class_name'])
                if match:
                    custom_name, confidence = match
                    remembered_objects.append({
                        'custom_name': custom_name,
                        'confidence': confidence,
                        'bbox': obj['bbox']
                    })
                    
                    # Map this object to its custom name
                    obj_id = id(obj)
                    object_to_custom_name[obj_id] = custom_name
                    
                    # Draw custom label
                    x1, y1, x2, y2 = obj['bbox']
                    label = f"{custom_name} ({confidence:.0%})"
                    cv2.rectangle(display, (x1, y1-30), (x1+len(label)*10, y1), (255, 0, 255), -1)
                    cv2.putText(display, label, (x1, y1-10),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
                    
                    # Audio announcement with cooldown
                    if audio_enabled:
                        current_time = time.time()
                        if custom_name not in last_remembered_announce or \
                           (current_time - last_remembered_announce[custom_name]) > remember_announce_cooldown:
                            audio.speak_social(f"Found your {custom_name}")
                            last_remembered_announce[custom_name] = current_time
                    
                    # Update sighting with custom names for nearby objects and faces
                    nearby = []
                    for o in objects:
                        if o != obj:
                            # Use custom name if recognized, otherwise use YOLO class
                            nearby_name = object_to_custom_name.get(id(o), o['class_name'])
                            nearby.append(nearby_name)
                    
                    # Add recognized face names to nearby list
                    nearby.extend(last_recognized_faces)
                    
                    object_memory.update_object_sighting(
                        custom_name=custom_name,
                        image=frame,
                        nearby_objects=nearby[:5],
                        confidence=confidence
                    )
        
        # 2. Face Recognition (every 3 frames for better multi-person detection)
        if frame_count % 3 == 0:
            faces = face_recognizer.recognize_faces(frame)
            display = face_recognizer.draw_faces(display, faces)
            
            # Store recognized face names for nearby context
            last_recognized_faces = [face['name'] for face in faces if face['name'] != 'Unknown']
            
            # Audio for recognized faces (with cooldown to avoid spam)
            if audio_enabled:
                current_time = time.time()
                for face in faces:
                    if face['name'] != 'Unknown':
                        # Only announce if not announced recently
                        if face['name'] not in last_face_announce or \
                           (current_time - last_face_announce[face['name']]) > face_announce_interval:
                            audio.speak_social(f"Hello {face['name']}")
                            last_face_announce[face['name']] = current_time
        
        # 3. Traffic Signal Detection - DISABLED (too many false positives)
        # traffic_signal = traffic_detector.detect_signal(frame)
        # if traffic_signal:
        #     display = traffic_detector.draw_signal(display, traffic_signal)
        #     
        #     # Emergency audio for red light
        #     if audio_enabled and traffic_signal['signal_type'] == 'RED':
        #         audio.speak_emergency("STOP - Red Light")
        
        # 4. Item Tracking
        item_updates = item_tracker.update_tracking(objects)
        if item_updates and audio_enabled:
            for update in item_updates:
                audio.speak_status(f"{update['item']} on {update['location']}")
        
        # 5. Object Enrollment Mode
        if enrollment_mode and enrollment_target_obj:
            # Find the target object in current detections
            target_detections = [o for o in objects if o['class_name'] == enrollment_target_obj['yolo_class']]
            
            if target_detections:
                # Use the first detection
                det = target_detections[0]
                bbox = (det['bbox'][0], det['bbox'][1], det['bbox'][2], det['bbox'][3])
                
                # Add to enrollment
                enrollment_frames_captured = object_memory.add_enrollment_frame(frame, bbox)
                
                # Visual feedback
                x1, y1, x2, y2 = det['bbox']
                cv2.rectangle(display, (x1, y1), (x2, y2), (255, 0, 255), 3)
                label = f"Recording {enrollment_frames_captured}/5"
                cv2.putText(display, label, (x1, y1-10),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)
                
                # Check if done
                if enrollment_frames_captured >= 5:
                    success = object_memory.finish_enrollment()
                    if success:
                        print(f"\u2713 Enrolled '{enrollment_target_obj['custom_name']}'")
                        if audio_enabled:
                            audio.speak_social(f"Remembered your {enrollment_target_obj['custom_name']}")
                    else:
                        print(f"\u2717 Enrollment failed - try again")
                    enrollment_mode = False
                    enrollment_target_obj = None
                    enrollment_frames_captured = 0
            else:
                # Show message if object not in view
                cv2.putText(display, f"Waiting for {enrollment_target_obj['yolo_class']}...",
                           (10, 200), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        
        # 5. Spatial Navigation for Obstacles
        if navigation_enabled and audio_enabled and not enrollment_mode:
            # Generate spatial guidance
            guidance = spatial_nav.generate_guidance(objects)
            
            # Announce highest priority guidance (with cooldown)
            current_time = time.time()
            if guidance and (current_time - last_navigation_announce) > navigation_announce_cooldown:
                # Take the top priority message
                top_guidance = guidance[0]
                
                # Map priority to audio level
                if top_guidance['priority'] == 1:
                    audio.speak_emergency(top_guidance['message'])
                else:
                    audio.speak_navigational(top_guidance['message'])
                
                last_navigation_announce = current_time
            
            # Draw guidance overlay on screen
            if guidance:
                y_offset = 100
                for g in guidance[:3]:  # Show top 3 guidance messages
                    color = (0, 0, 255) if g['priority'] == 1 else (0, 165, 255)  # Red for emergency, orange for normal
                    cv2.putText(display, g['message'], (10, y_offset),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
                    y_offset += 25
        
        # 6. GPS Navigation Update
        if gps_navigation_active and osm_nav.current_route:
            current_time = time.time()
            
            # Update GPS navigation every 2 seconds
            if (current_time - last_gps_update) >= gps_update_interval:
                last_gps_update = current_time
                
                # Get current position
                current_pos = gps_tracker.get_position()
                if current_pos:
                    # Get current instruction
                    if gps_nav_step < len(osm_nav.current_route['steps']):
                        step = osm_nav.current_route['steps'][gps_nav_step]
                        instruction = step['instruction']
                        
                        # Calculate distance to waypoint
                        end_lat = step['end_location']['lat']
                        end_lon = step['end_location']['lng']
                        
                        import math
                        # Haversine distance calculation
                        R = 6371000  # Earth radius in meters
                        lat1, lon1 = current_pos
                        lat2, lon2 = end_lat, end_lon
                        phi1 = math.radians(lat1)
                        phi2 = math.radians(lat2)
                        delta_phi = math.radians(lat2 - lat1)
                        delta_lambda = math.radians(lon2 - lon1)
                        a = math.sin(delta_phi / 2) ** 2 + math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda / 2) ** 2
                        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
                        distance = R * c
                        
                        # Check if should announce
                        if distance <= config.NAVIGATION_ANNOUNCEMENT_DISTANCE:
                            if last_gps_announcement != gps_nav_step:
                                last_gps_announcement = gps_nav_step
                                if audio_enabled:
                                    audio.speak_navigational(f"In {int(distance)} meters, {instruction}")
                                print(f"\nðŸ”Š GPS: {instruction} ({distance:.0f}m)")
                        
                        # Display navigation info on screen
                        total_steps = len(osm_nav.current_route['steps'])
                        nav_text = f"GPS NAV [{gps_nav_step + 1}/{total_steps}]: {instruction[:60]}"
                        cv2.rectangle(display, (5, 125), (635, 175), (0, 0, 0), -1)  # Black background
                        cv2.putText(display, nav_text, (10, 145),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)
                        cv2.putText(display, f"Distance: {distance:.0f}m", (10, 165),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)
                        
                        # Advance to next step if close
                        if distance < 10:
                            if gps_nav_step + 1 < len(osm_nav.current_route['steps']):
                                gps_nav_step += 1
                                last_gps_announcement = None
                                print(f"âœ“ Advanced to step {gps_nav_step + 1}")
                            else:
                                # Arrived!
                                if audio_enabled:
                                    audio.speak_social("You have arrived at your destination")
                                print("\nâœ“ GPS Navigation: ARRIVED!")
                                gps_navigation_active = False
                    
                    # Enhanced obstacle detection during GPS navigation
                    if audio_enabled:
                        # Use obstacle fusion for precise warnings
                        warnings = obstacle_fusion.generate_obstacle_warnings(objects)
                        if warnings:
                            highest = warnings[0]
                            if highest['priority'] <= 2:  # Emergency or High warning
                                # Don't spam - only announce critical obstacles
                                audio.speak_emergency(highest['message'])
        
        # Display stats
        elapsed = time.time() - start_time
        fps = frame_count / elapsed if elapsed > 0 else 0
        
        # Count recognized faces
        recognized_count = len([f for f in faces if f['name'] != 'Unknown']) if frame_count % 3 == 0 and 'faces' in locals() else 0
        
        stats = [
            f"FPS: {fps:.1f}",
            f"Objects: {len(objects)}",
            f"Remembered: {len(remembered_objects)}",
            f"Faces: {recognized_count}",
            f"Audio: {'ON' if audio_enabled else 'OFF'}",
            f"Navigation: {'ON' if navigation_enabled else 'OFF'}",
            f"Voice: {'ON' if voice_mode_enabled and voice_system else 'OFF'}",
            f"Queue: {audio.get_queue_size()}"
        ]
        
        for i, stat in enumerate(stats):
            cv2.putText(
                display,
                stat,
                (10, 30 + i * 25),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (0, 255, 0),
                2
            )
        
        # Controls
        if enrollment_mode:
            cv2.putText(
                display,
                f"ENROLLING: {enrollment_target_obj['custom_name']} - Hold steady!",
                (10, display.shape[0] - 50),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (255, 0, 255),
                2
            )
        
        cv2.putText(
            display,
            "Q:Quit | E:Face | R:Remember | L:List | F:Find | A:Audio | N:Nav | V:Voice | SPACE:Talk",
            (10, display.shape[0] - 20),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.45,
            (255, 255, 255),
            1
        )
        
        cv2.imshow('VisionMate Integration Test', display)
        
        key = cv2.waitKey(1) & 0xFF
        
        if key == ord('q'):
            break
        elif key == ord('e'):
            # Enroll face
            name = input("\nEnter name for enrollment: ").strip()
            if name:
                success = face_recognizer.enroll_face(frame, name)
                if success:
                    print(f"âœ“ Enrolled {name}")
                    if audio_enabled:
                        audio.speak_social(f"Enrolled {name}")
        elif key == ord('r'):
            # Remember object
            if not enrollment_mode:
                # Show available objects
                if objects:
                    print("\nDetected objects:")
                    for i, obj in enumerate(objects):
                        print(f"  {i+1}. {obj['class_name']}")
                    
                    # Get selection
                    try:
                        idx = int(input("Select object number: ").strip()) - 1
                        if 0 <= idx < len(objects):
                            obj = objects[idx]
                            custom_name = input("Enter custom name (e.g., 'house keys'): ").strip()
                            
                            if custom_name:
                                try:
                                    object_memory.start_enrollment(custom_name, obj['class_name'])
                                    enrollment_mode = True
                                    enrollment_target_obj = {
                                        'custom_name': custom_name,
                                        'yolo_class': obj['class_name']
                                    }
                                    print(f"\u2713 Starting enrollment for '{custom_name}'...")
                                    print("  Keep object in view, capturing 5 frames...")
                                except ValueError as e:
                                    print(f"\u2717 {e}")
                    except (ValueError, IndexError):
                        print("\u2717 Invalid selection")
                else:
                    print("\u2717 No objects detected")
        elif key == ord('l'):
            # List remembered objects
            remembered_list = object_memory.list_remembered_objects()
            print(f"\nRemembered Objects ({len(remembered_list)}):")
            if remembered_list:
                for name, yolo_class in remembered_list:
                    print(f"  - {name} ({yolo_class})")
            else:
                print("  (none)")
        elif key == ord('f'):
            # Query object/item
            item = input("\nEnter item/object to find: ").strip()
            if item:
                # Try remembered objects first
                location = object_memory.get_object_location(item)
                if location:
                    nearby = location['context'].get('nearby_objects', []) if location['context'] else []
                    nearby_str = f" near {', '.join(nearby)}" if nearby else ""
                    msg = f"Your {item} last seen{nearby_str}"
                    print(f"âœ“ {msg}")
                    print(f"  Time: {location['timestamp']}")
                    if audio_enabled:
                        audio.speak_navigational(msg)
                else:
                    # Try regular item tracker
                    loc = item_tracker.query_item_location(item)
                    if loc:
                        msg = f"Your {item} are on the {loc}"
                        print(f"âœ“ {msg}")
                        if audio_enabled:
                            audio.speak_navigational(msg)
                    else:
                        print(f"âœ— Haven't seen {item}")
        elif key == ord('a'):
            audio_enabled = not audio_enabled
            print(f"\nðŸ”Š Audio feedback: {'ON' if audio_enabled else 'OFF'}")
        elif key == ord('n'):
            navigation_enabled = not navigation_enabled
            print(f"\nðŸ§­ Navigation guidance: {'ON' if navigation_enabled else 'OFF'}")
        elif key == ord('g'):
            # Start GPS navigation
            if not gps_navigation_active:
                destination = input("\nEnter destination (e.g., 'Majestic'): ").strip()
                if destination:
                    print(f"\nðŸ—ºï¸ Starting GPS navigation to {destination}...")
                    if audio_enabled:
                        audio.speak_social(f"Navigating to {destination}")
                    
                    # Geocode destination
                    dest_coords = osm_nav.geocode_address(destination + ", Bangalore, India")
                    if not dest_coords:
                        print("âœ— Could not find destination")
                        if audio_enabled:
                            audio.speak_status("Could not find destination")
                    else:
                        # Get current position
                        current_pos = gps_tracker.get_position()
                        if not current_pos:
                            print("âœ— Waiting for GPS signal")
                            if audio_enabled:
                                audio.speak_status("Waiting for GPS signal")
                        else:
                            # Get directions
                            route = osm_nav.get_directions(current_pos, dest_coords, mode='foot')
                            if route:
                                osm_nav.current_route = route
                                gps_navigation_active = True
                                gps_nav_step = 0
                                last_gps_announcement = None
                                print(f"âœ“ Route found: {route['total_distance']}, {route['total_duration']}")
                                print(f"  Steps: {len(route['steps'])}")
                                if audio_enabled:
                                    audio.speak_social(f"Route found. {route['total_distance']}. {route['total_duration']}.")
                            else:
                                print("âœ— Could not find route")
                                if audio_enabled:
                                    audio.speak_status("Could not find route")
            else:
                # Stop GPS navigation
                gps_navigation_active = False
                print("\nðŸ—ºï¸ GPS navigation stopped")
                if audio_enabled:
                    audio.speak_status("GPS navigation stopped")
        elif key == ord('m'):
            # Advance mock GPS position
            if config.GPS_MOCK_MODE:
                gps_tracker.advance_mock_position()
                new_pos = gps_tracker.get_position()
                print(f"\nðŸ“ Mock GPS advanced to: {new_pos[0]:.6f}, {new_pos[1]:.6f}")
            else:
                print("\nâš  GPS is in REAL mode, not mock mode")
        elif key == ord('v'):
            # Toggle voice mode
            if voice_system:
                voice_mode_enabled = not voice_mode_enabled
                status = "ON" if voice_mode_enabled else "OFF"
                print(f"\nðŸŽ¤ Voice mode: {status}")
                if audio_enabled:
                    audio.speak_status(f"Voice mode {status}")
            else:
                print("\nâš  Voice system not available")
        elif key == 32:  # SPACEBAR
            # Trigger voice input (button simulation)
            if voice_system and voice_mode_enabled:
                print("\nðŸŽ¤ Listening for voice command...")
                if audio_enabled:
                    audio.speak_status("Listening")
                voice_system.trigger_voice_input()
            else:
                if not voice_system:
                    print("\nâš  Voice system not available")
                else:
                    print("\nâš  Voice mode is OFF - press V to enable")
    
    cap.release()
    cv2.destroyAllWindows()
    
    # Cleanup navigation services
    gps_tracker.stop()
    ultrasonic.stop()
    
    # Cleanup voice system
    if voice_system:
        voice_system.stop()
    
    print("\n" + "=" * 60)
    print("INTEGRATION TEST COMPLETE")
    print("=" * 60)
    print(f"Total frames processed: {frame_count}")
    print(f"Average FPS: {fps:.2f}")
    print(f"Total time: {elapsed:.2f}s")
    print("=" * 60)
    
    db.close()


def test_priority_system():
    """Test audio feedback priority system"""
    print("=" * 60)
    print("TESTING AUDIO PRIORITY SYSTEM")
    print("=" * 60)
    
    audio = get_audio_feedback(use_gtts=False)
    
    print("\nTesting priority hierarchy...")
    print("Order: STATUS -> NAVIGATIONAL -> SOCIAL -> EMERGENCY")
    
    # Queue messages in different priorities
    audio.speak_status("Battery low")
    time.sleep(0.5)
    audio.speak_navigational("Chair ahead")
    time.sleep(0.5)
    audio.speak_social("Hello John")
    time.sleep(0.5)
    audio.speak_emergency("STOP - Red Light")  # Should interrupt
    
    print("\nEmergency message should play immediately and interrupt others")
    print("âœ“ Priority test queued!")
    
    # Wait for audio to finish
    time.sleep(10)


def test_database_integration():
    """Test database with all components"""
    print("=" * 60)
    print("TESTING DATABASE INTEGRATION")
    print("=" * 60)
    
    db = VisionMateDB()
    
    # Check faces
    faces = db.get_all_faces()
    print(f"\nâœ“ Faces in database: {len(faces)}")
    for face_id, name, _ in faces:
        print(f"  - {name} (ID: {face_id})")
    
    # Check item locations
    items = db.get_all_item_locations()
    print(f"\nâœ“ Item locations in database: {len(items)}")
    for item, location, timestamp in items:
        print(f"  - {item} on {location} (at {timestamp})")
    
    # Check remembered objects
    remembered = db.get_all_remembered_objects()
    print(f"\nâœ“ Remembered objects in database: {len(remembered)}")
    for obj_id, name, yolo_class in remembered:
        print(f"  - {name} ({yolo_class}) [ID: {obj_id}]")
    
    db.close()
    print("\nâœ“ Database integration test complete!")


if __name__ == "__main__":
    print("\nVISIONMATE INTEGRATION TEST SUITE")
    print("=" * 60)
    
    print("\nSelect test mode:")
    print("1. Full pipeline with webcam (recommended)")
    print("2. Audio priority system test")
    print("3. Database integration test")
    print("4. All tests")
    
    choice = input("\nEnter choice (1-4): ").strip()
    
    if choice == '1':
        test_full_pipeline_webcam()
    elif choice == '2':
        test_priority_system()
    elif choice == '3':
        test_database_integration()
    elif choice == '4':
        test_database_integration()
        print("\n")
        test_priority_system()
        print("\n")
        test_full_pipeline_webcam()
    else:
        print("Running full pipeline test...")
        test_full_pipeline_webcam()
